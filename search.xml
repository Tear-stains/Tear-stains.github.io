<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx全解析]]></title>
    <url>%2F2020%2F09%2F17%2FNginx%E5%85%A8%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Nginx什么是nginxNginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。 在高连接并发的情况下，Nginx是Apache服务器不错的替代品。 什么是反向代理反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源。同时，用户不需要知道目标服务器的地址，也无须在用户端作任何设定。反向代理服务器通常可用来作为Web加速，即使用反向代理作为Web服务器的前置机来降低网络和服务器的负载，提高访问效率。 简单的说就是用户请求反向代理服务器，反向代理服务器做请求分发，决定用户访问哪个服务器ip 安装Nginx与运行 去官网http://nginx.org/下载对应的nginx包，推荐使用稳定版本 上传nginx到linux系统 安装依赖环境 (1)安装gcc环境 1yum install gcc-c++ (2)安装PCRE库，用于解析正则表达式 1yum install -y pcre pcre-devel (3)zlib压缩和解压缩依赖， 1yum install -y zlib zlib-devel (4)SSL 安全的加密的套接字协议层，用于HTTP安全传输，也就是https 1yum install -y openssl openssl-devel 解压，需要注意，解压后得到的是源码，源码需要编译后才能安装 1tar -zxvf nginx-1.16.1.tar.gz 编译之前，先创建nginx临时目录，如果不创建，在启动nginx的过程中会报错 1mkdir /var/temp/nginx -p 在nginx目录，输入如下命令进行配置，目的是为了创建makefile文件 1./configure \n --prefix=/usr/local/nginx \n --pid-path=/var/run/nginx/nginx.pid \n --lock-path=/var/lock/nginx.lock \n --error-log-path=/var/log/nginx/error.log \n --http-log-path=/var/log/nginx/access.log \n --with-http_gzip_static_module \n --http-client-body-temp-path=/var/temp/nginx/client \n --http-proxy-temp-path=/var/temp/nginx/proxy \n --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \n --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \n --http-scgi-temp-path=/var/temp/nginx/scgi 注： 代表在命令行中换行，用于提高可读性 配置命令： 命令 解释 –prefix 指定nginx安装目录 –pid-path 指向nginx的pid –lock-path 锁定安装文件，防止被恶意篡改或误操作 –error-log 错误日志 –http-log-path http日志 –with-http_gzip_static_module 启用gzip模块，在线实时压缩输出数据流 –http-client-body-temp-path 设定客户端请求的临时目录 –http-proxy-temp-path 设定http代理临时目录 –http-fastcgi-temp-path 设定fastcgi临时目录 –http-uwsgi-temp-path 设定uwsgi临时目录 –http-scgi-temp-path 设定scgi临时目录 make编译 1make 安装 1make install 进入sbin目录启动nginx 1./nginx 停止：./nginx -s stop 重新加载：./nginx -s reload 打开浏览器，访问虚拟机所处内网ip即可打开nginx默认页面，显示正常便表示安装成功。 注意事项: 如果在云服务器安装，需要开启默认的nginx端口：80 如果在虚拟机安装，需要关闭防火墙 本地win或mac需要关闭防火墙 nginx.conf 核心配置文件 设置worker进程的用户，指的linux中的用户，会涉及到nginx操作目录或文件的一些权限，默认为nobody 1user root; worker进程工作数设置，一般来说CPU有几个，就设置几个，或者设置为N-1也行 1worker_processes 1; nginx 日志级别debug | info | notice | warn | error | crit | alert | emerg，错误级别从左到右越来越大 设置nginx进程 pid 1pid logs/nginx.pid; 设置工作模式 123456events &#123; # 默认使用epoll use epoll; # 每个worker允许连接的客户端最大连接数 worker_connections 10240;&#125; http 是指令块，针对http网络传输的一些指令配置 12http &#123;&#125; include 引入外部配置，提高可读性，避免单个配置文件过大 1include mime.types; 设定日志格式，main为定义的格式名称，如此 access_log 就可以直接使用这个变量了 参数名 参数意义 $remote_addr 客户端ip $remote_user 远程客户端用户名，一般为：’-’ $time_local 时间和时区 $request 请求的url以及method $status 响应状态码 $body_bytes_send 响应客户端内容字节数 $http_referer 记录用户从哪个链接跳转过来的 $http_user_agent 用户所使用的代理，一般来时都是浏览器 $http_x_forwarded_for 通过代理服务器来记录客户端的ip sendfile使用高效文件传输，提升传输性能。启用后才能使用tcp_nopush，是指当数据表累积一定大小后才发送，提高了效率。 12sendfile on;tcp_nopush on; keepalive_timeout设置客户端与服务端请求的超时时间，保证客户端多次请求的时候不会重复建立新的连接，节约资源损耗。 12#keepalive_timeout 0;keepalive_timeout 65; gzip启用压缩，html/js/css压缩后传输会更快 1gzip on; server可以在http指令块中设置多个虚拟主机 listen 监听端口 server_name localhost、ip、域名 location 请求路由映射，匹配拦截 root 请求位置 index 首页设置 123456789server &#123; listen 88; server_name localhost; location / &#123; root html; index index.html index.htm; &#125;&#125; location 的匹配规则 空格：默认匹配，普通匹配 123location / &#123; root /home;&#125; =：精确匹配 123location = /gy/img/face1.png &#123; root /home;&#125; ~*：匹配正则表达式，不区分大小写 1234#符合图片的显示location ~* .(GIF|jpg|png|jpeg) &#123; root /home;&#125; ~：匹配正则表达式，区分大小写 1234#GIF必须大写才能匹配到location ~ .(GIF|jpg|png|jpeg) &#123; root /home;&#125; ^~：以某个字符路径开头 123location ^~ /gy/img &#123; root /home;&#125; root 与 alias假如服务器路径为：/home/gy/files/img/face.png root 路径完全匹配访问配置的时候为： 123location /gy &#123; root /home&#125; 用户访问的时候请求为：url:port/gy/files/img/face.png alias 可以为你的路径做一个别名，对用户透明配置的时候为： 123location /hello &#123; alias /home/gy&#125; 用户访问的时候请求为：url:port/hello/files/img/face.png，如此相当于为目录gy做一个自定义的别名。 Nginx 日志切割-手动现有的日志都会存在 access.log 文件中，但是随着时间的推移，这个文件的内容会越来越多，体积会越来越大，不便于运维人员查看，所以我们可以通过把这个大的日志文件切割为多份不同的小文件作为日志，切割规则可以以天为单位，如果每天有几百G或者几个T的日志的话，则可以按需以每半天或者每小时对日志切割一下。 具体步骤如下： 创建一个shell可执行文件：cut_my_log.sh，内容为： 123456789#!/bin/bashLOG_PATH="/var/log/nginx/"RECORD_TIME=$(date -d "yesterday" +%Y-%m-%d+%H:%M)PID=/var/run/nginx/nginx.pidmv $&#123;LOG_PATH&#125;/access.log $&#123;LOG_PATH&#125;/access.$&#123;RECORD_TIME&#125;.logmv $&#123;LOG_PATH&#125;/error.log $&#123;LOG_PATH&#125;/error.$&#123;RECORD_TIME&#125;.log#向Nginx主进程发送信号，用于重新打开日志文件kill -USR1 `cat $PID` 为cut_my_log.sh添加可执行的权限： 1chmod +x cut_my_log.sh 测试日志切割后的结果: 1./cut_my_log.sh Nginx 日志切割-定时使用定时任务 安装定时任务： 1yum install crontabs crontab -e 编辑并且添加一行新的任务： 1*/1 * * * * /usr/local/nginx/sbin/cut_my_log.sh 重启定时任务： 1service crond restart 附：常用定时任务命令： 123456service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置crontab -e // 编辑任务crontab -l // 查看任务列表 定时任务表达式：Cron表达式是，分为5或6个域，每个域代表一个含义，如下所示： 分 时 日 月 星期几 年（可选） 取值范围 0-59 0-23 1-31 1-12 1-7 2019/2020/2021/… 常用表达式： 每分钟执行： 1*/1 * * * * 每日凌晨（每天晚上23:59）执行： 159 23 * * * 每日凌晨1点执行： 10 1 * * * Nginx 跨域配置支持12345678#允许跨域请求的域，*代表所有add_header 'Access-Control-Allow-Origin' *;#允许带上cookie请求add_header 'Access-Control-Allow-Credentials' 'true';#允许请求的方法，比如 GET/POST/PUT/DELETEadd_header 'Access-Control-Allow-Methods' *;#允许请求的headeradd_header 'Access-Control-Allow-Headers' *; Nginx 防盗链配置支持123456#对源站点验证valid_referers *.gy.com; #非法引入会进入下方判断if ($invalid_referer) &#123; return 404;&#125; upstream 指令参数 max_conns限制每台server的连接数，用于保护避免过载，可起到限流作用。测试参考配置如下： 12345678# worker进程设置1个，便于测试观察成功的连接数worker_processes 1;upstream tomcats &#123; server 192.168.1.173:8080 max_conns=2; server 192.168.1.174:8080 max_conns=2; server 192.168.1.175:8080 max_conns=2;&#125; upstream 指令参数 slow_start商业版，需要付费配置参考如下： 123456upstream tomcats &#123; server 192.168.1.173:8080 weight=6 slow_start=60s;# server 192.168.1.190:8080; server 192.168.1.174:8080 weight=2; server 192.168.1.175:8080 weight=2;&#125; 注意 该参数不能使用在hash和random load balancing中。 如果在 upstream 中只有一台 server，则该参数失效。 upstream 指令参数 down、backupdown 用于标记服务节点不可用： 123456upstream tomcats &#123; server 192.168.1.173:8080 down;# server 192.168.1.190:8080; server 192.168.1.174:8080 weight=1; server 192.168.1.175:8080 weight=1;&#125; backup表示当前服务器节点是备用机，只有在其他的服务器都宕机以后，自己才会加入到集群中，被用户访问到： 123456upstream tomcats &#123; server 192.168.1.173:8080 backup;# server 192.168.1.190:8080; server 192.168.1.174:8080 weight=1; server 192.168.1.175:8080 weight=1;&#125; 注意 backup参数不能使用在hash和random load balancing中。 upstream 指令参数 max_fails、fail_timeoutmax_fails：表示失败几次，则标记server已宕机，剔出上游服务。fail_timeout：表示失败的重试时间。假设目前设置如下： 1max_fails=2 fail_timeout=15s 则代表在15秒内请求某一server失败达到2次后，则认为该server已经挂了或者宕机了，随后再过15秒，这15秒内不会有新的请求到达刚刚挂掉的节点上，而是会请求到正常运作的server，15秒后会再有新请求尝试连接挂掉的server，如果还是失败，重复上一过程，直到恢复。 Keepalived 提高吞吐量keepalived： 设置长连接处理的数量proxy_http_version：设置长连接http版本为1.1proxy_set_header：清除connection header 信息 123456789101112131415161718upstream tomcats &#123;# server 192.168.1.173:8080 max_fails=2 fail_timeout=1s; server 192.168.1.190:8080;# server 192.168.1.174:8080 weight=1;# server 192.168.1.175:8080 weight=1; keepalive 32;&#125;server &#123; listen 80; server_name www.tomcats.com; location / &#123; proxy_pass http://tomcats; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125; 负载均衡 ip_haship_hash 可以保证用户访问可以请求到上游服务中的固定的服务器，前提是用户ip没有发生更改。使用ip_hash的注意点：不能把后台服务器直接移除，只能标记down. If one of the servers needs to be temporarily removed, it should be marked with the down parameter in order to preserve the current hashing of client IP addresses. 1234567upstream tomcats &#123; ip_hash; server 192.168.1.173:8080; server 192.168.1.174:8080 down; server 192.168.1.175:8080;&#125; 负载均衡 url_hash 与 least_conn根据每次请求的url地址，hash后访问到固定的服务器节点。 1234567891011121314151617181920upstream tomcats &#123; # url hash hash $request_uri; # 最少连接数 # least_conn server 192.168.1.173:8080; server 192.168.1.174:8080; server 192.168.1.175:8080;&#125;server &#123; listen 80; server_name www.tomcats.com; location / &#123; proxy_pass http://tomcats; &#125;&#125; Nginx的缓存 浏览器缓存： 加速用户访问，提升单个用户（浏览器访问者）体验，缓存在本地 Nginx缓存 缓存在nginx端，提升所有访问到nginx这一端的用户 提升访问上游（upstream）服务器的速度 用户访问仍然会产生请求流量 控制浏览器缓存： 123456789location /files &#123; alias /home/imooc; # expires 10s; # expires @22h30m; # expires -1h; # expires epoch; # expires off; expires max;&#125; Nginx的反向代理缓存1234567891011121314# proxy_cache_path 设置缓存目录# keys_zone 设置共享内存以及占用空间大小# max_size 设置缓存大小# inactive 超过此时间则被清理# use_temp_path 临时目录，使用后会影响nginx性能proxy_cache_path /usr/local/nginx/upstream_cache keys_zone=mycache:5m max_size=1g inactive=1m use_temp_path=off;location / &#123; proxy_pass http://tomcats; # 启用缓存，和keys_zone一致 proxy_cache mycache; # 针对200和304状态码缓存时间为8小时 proxy_cache_valid 200 304 8h;&#125; 使用Nginx配置HTTPS域名证书1. 安装SSL模块要在nginx中配置https，就必须安装ssl模块，也就是: http_ssl_module。 进入到nginx的解压目录： /home/software/nginx-1.16.1 新增ssl模块(原来的那些模块需要保留) 12345678910111213./configure \--prefix=/usr/local/nginx \--pid-path=/var/run/nginx/nginx.pid \--lock-path=/var/lock/nginx.lock \--error-log-path=/var/log/nginx/error.log \--http-log-path=/var/log/nginx/access.log \--with-http_gzip_static_module \--http-client-body-temp-path=/var/temp/nginx/client \--http-proxy-temp-path=/var/temp/nginx/proxy \--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \--http-scgi-temp-path=/var/temp/nginx/scgi \--with-http_ssl_module 编译和安装 123makemake install 2. 配置HTTPS 把ssl证书 *.crt 和 私钥 *.key 拷贝到/usr/local/nginx/conf目录中。 新增 server 监听 443 端口： 1234567891011121314151617181920212223242526server &#123; listen 443; server_name www.skyy.com; # 开启ssl ssl on; # 配置ssl证书 ssl_certificate skyy.com.crt; # 配置证书秘钥 ssl_certificate_key skyy.com.key; # ssl会话cache ssl_session_cache shared:SSL:1m; # ssl会话超时时间 ssl_session_timeout 5m; # 配置加密套件，写法遵循 openssl 标准 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / &#123; proxy_pass http://tomcats/; index index.html index.htm; &#125; &#125; 3. reload nginx1./nginx -s reload]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx搭建文件服务器实现文件上传]]></title>
    <url>%2F2020%2F07%2F06%2FNginx%E6%90%AD%E5%BB%BA%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[Nginx搭建文件服务器实现文件上传安装Nginx 去官网http://nginx.org/下载对应的nginx包，推荐使用稳定版本 上传nginx到linux系统 安装依赖环境 (1)安装gcc环境 1yum install gcc-c++ (2)安装PCRE库，用于解析正则表达式 1yum install -y pcre pcre-devel (3)zlib压缩和解压缩依赖， 1yum install -y zlib zlib-devel (4)SSL 安全的加密的套接字协议层，用于HTTP安全传输，也就是https 1yum install -y openssl openssl-devel 解压，需要注意，解压后得到的是源码，源码需要编译后才能安装 1tar -zxvf nginx-1.16.1.tar.gz 编译之前，先创建nginx临时目录，如果不创建，在启动nginx的过程中会报错 1mkdir /var/temp/nginx -p 在nginx目录，输入如下命令进行配置，目的是为了创建makefile文件 1./configure \n --prefix=/usr/local/nginx \n --pid-path=/var/run/nginx/nginx.pid \n --lock-path=/var/lock/nginx.lock \n --error-log-path=/var/log/nginx/error.log \n --http-log-path=/var/log/nginx/access.log \n --with-http_gzip_static_module \n --http-client-body-temp-path=/var/temp/nginx/client \n --http-proxy-temp-path=/var/temp/nginx/proxy \n --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \n --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \n --http-scgi-temp-path=/var/temp/nginx/scgi 配置命令： 命令 解释 –prefix 指定nginx安装目录 –pid-path 指向nginx的pid –lock-path 锁定安装文件，防止被恶意篡改或误操作 –error-log 错误日志 –http-log-path http日志 –with-http_gzip_static_module 启用gzip模块，在线实时压缩输出数据流 –http-client-body-temp-path 设定客户端请求的临时目录 –http-proxy-temp-path 设定http代理临时目录 –http-fastcgi-temp-path 设定fastcgi临时目录 –http-uwsgi-temp-path 设定uwsgi临时目录 –http-scgi-temp-path 设定scgi临时目录 make编译 1make 安装 1make install 进入sbin目录启动nginx 1./nginx 停止：./nginx -s stop 重新加载：./nginx -s reload 修改配置文件 切换至安装目录 1cd /usr/local/nginx/conf 修改文件 1vim nginx.conf 主要是修改server配置节的内容,配置文件路径 location ~.* { #可识别的文件 root /usr/local/nginx/image/; #图片的映射路径 autoindex on; #开启自动索引 expires 1h; #过期时间 }重启nginx 1./nginx -s reload 上传文件功能实现pom.xml12345&lt;dependency&gt; &lt;groupId&gt;com.jcraft&lt;/groupId&gt; &lt;artifactId&gt;jsch&lt;/artifactId&gt; &lt;version&gt;0.1.54&lt;/version&gt;&lt;/dependency&gt; application.yml1234567891011121314# ftp 服务器配置ftp: # 服务器地址 fileUrl: http://10.10.10.15:80/ # 服务器ip host: 10.10.10.15 # 服务器登录用户名 userName: root # 服务器密码 password: Sq6sQJXDyTQo # 服务器端口号 port: 22 # 文件存储路径 rootPath: /usr/local/nginx/file 核心工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148@Componentpublic class FtpUtil &#123; private static final Logger logger = LoggerFactory.getLogger(FtpUtil.class); /** * ftp服务器ip地址 */ private static String host; /** * 端口 */ private static int port; /** * 用户名 */ private static String userName; /** * 密码 */ private static String password; /** * 存放文件的根目录 */ private static String rootPath; /** * 存放文件的路径 */ private static String fileUrl; @Value("$&#123;ftp.host&#125;") public void setHost(String host) &#123; FtpUtil.host = host; &#125; @Value("$&#123;ftp.port&#125;") public void setPort(int port) &#123; FtpUtil.port = port; &#125; @Value("$&#123;ftp.userName&#125;") public void setUserName(String userName) &#123; FtpUtil.userName = userName; &#125; @Value("$&#123;ftp.password&#125;") public void setPassword(String password) &#123; FtpUtil.password = password; &#125; @Value("$&#123;ftp.rootPath&#125;") public void setRootPath(String rootPath) &#123; FtpUtil.rootPath = rootPath; &#125; @Value("$&#123;ftp.fileUrl&#125;") public void setFileUrl(String fileUrl) &#123; FtpUtil.fileUrl = fileUrl; &#125; private static ChannelSftp getChannel() throws Exception &#123; JSch jsch = new JSch(); // -&gt;ssh root@host:port Session sshSession = jsch.getSession(userName, host, port); // 密码 sshSession.setPassword(password); Properties sshConfig = new Properties(); // 设置第一次登陆的时候提示，可选值：(ask | yes | no) sshSession.setConfig("StrictHostKeyChecking", "no"); sshSession.setConfig(sshConfig); //设置登陆超时时间 // 注意！！这里不设置超时间会报错 sshSession.connect(60000); Channel channel = sshSession.openChannel("sftp"); channel.connect(1000); return (ChannelSftp) channel; &#125; /** * ftp上传文件 * * @param inputStream 文件io流 * @param imagePath 路径，不存在就创建目录 * @param imagesName 文件名称 * @return urlStr 文件的存放路径 */ public static String putFile(InputStream inputStream, String fileName, String type) &#123; try &#123; ChannelSftp sftp = getChannel(); String path = rootPath + "/" + type + "/"; createDir(path, sftp); // 上传文件 sftp.put(inputStream, path + fileName); logger.info("上传成功！"); sftp.quit(); sftp.exit(); // 处理返回的路径 String resultFile; resultFile = fileUrl + type + "/" + fileName; return resultFile; &#125; catch (Exception e) &#123; logger.error("上传失败：" + e.getMessage()); &#125; return ""; &#125; /** * 创建目录 */ private static void createDir(String path, ChannelSftp sftp) throws SftpException &#123; String[] folders = path.split("/"); sftp.cd("/"); for (String folder : folders) &#123; if (folder.length() &gt; 0) &#123; try &#123; sftp.cd(folder); &#125; catch (SftpException e) &#123; sftp.mkdir(folder); sftp.cd(folder); &#125; &#125; &#125; &#125; /** * 删除文件 */ public static void delFile(String fileName,String type) &#123; try &#123; ChannelSftp sftp = getChannel(); String path = rootPath + "/" + type + "/" + fileName; sftp.rm(path); sftp.quit(); sftp.exit(); &#125; catch (Exception e) &#123; logger.error(" 删除失败：" + e.getMessage()); &#125; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos7安装FastDFS详解]]></title>
    <url>%2F2020%2F07%2F03%2Fcentos7%E5%AE%89%E8%A3%85FastDFS%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[centos7安装FastDFS详解配置FastDFS环境准备工作参考文献FastDFS:https://github.com/happyfish100/ 官方安装文档：https://github.com/happyfish100/fastdfs/wiki 环境准备 Centos7.x 两台，分别安装tracker与storage 下载安装包： libfatscommon：FastDFS分离出的一些公用函数包 FastDFS：FastDFS本体 fastdfs-nginx-module：FastDFS和nginx的关联模块 nginx：发布访问服务 安装步骤 (tracker与storage两台服务器都要执行) 安装基础环境 12yum install -y gcc gcc-c++yum -y install libevent 安装libfatscommon函数库 12# 解压tar -zxvf libfastcommon-1.0.42.tar.gz 进入libfastcommon文件夹，编译并且安装 123cd libfastcommon-1.0.42./make.sh./make.sh install 安装fastdfs主程序文件 12# 解压tar -zxvf fastdfs-6.04.tar.gz 进入到fastdfs目录，安装fastdfs 123cd fastdfs-6.04/./make.sh./make.sh install 拷贝配置文件如下： 1cp /home/software/FastDFS/fastdfs-6.04/conf/* /etc/fdfs/ 配置tracker服务修改tracker配置文件1vim /etc/fdfs/tracker.conf 修改tracker配置文件，此为tracker的工作目录，保存数据以及日志 1base_path=/usr/local/fastdfs/tracker 创建tracker工作目录 1mkdir /usr/local/fastdfs/tracker -p 启动tracker服务1/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf 检查进程如下： 1ps -ef|grep tracker 停止tracker 1/usr/bin/stop.sh /etc/fdfs/tracker.conf 配置storage服务修改storage配置文件修改该storage.conf配置文件 1vim /etc/fdfs/storage.conf 12345678# 修改组名group_name=groupTest# 修改storage的工作空间base_path=/usr/local/fastdfs/storage# 修改storage的存储空间store_path0=/usr/local/fastdfs/storage# 修改tracker的地址和端口号，用于心跳tracker_server=(trackerip):22122 创建storage工作目录 1mkdir /usr/local/fastdfs/storage -p 启动storage前提：必须首先启动tracker 1/usr/bin/fdfs_storaged /etc/fdfs/storage.conf 检查进程如下： 1ps -ef|grep storage 测试上传(在storage服务器中操作)修改的client配置文件 1vim /etc/fdfs/client.conf 12base_path=/usr/local/fastdfs/clienttracker_server=(trackerip):22122 创建client工作目录 1mkdir /usr/local/fastdfs/client 测试： 1/usr/bin/fdfs_test /etc/fdfs/client.conf upload ./testUpload.jpg 查看上传的文件 1cd /usr/local/fastdfs/storage/data/00/00 配置nginx服务器fastdfs安装好以后是无法通过http访问的，这个时候就需要借助nginx了，所以需要安装fastdfs的第三方模块到nginx中，就能使用了。nginx需要和storage在同一个节点。 安装nginx插件解压nginx的fastdfs压缩包 1tar -zxvf fastdfs-nginx-module-1.22.tar.gz 复制配置文件如下： 1cp mod_fastdfs.conf /etc/fdfs 修改/fastdfs-nginx-module/src/config文件，主要是修改路径，把local删除，因为fastdfs安装的时候我们没有修改路径，原路径是/usr/local/incloud 安装nginx 去官网http://nginx.org/下载对应的nginx包，推荐使用稳定版本 上传nginx到linux系统 安装依赖环境 (1)安装gcc环境 1yum install gcc-c++ (2)安装PCRE库，用于解析正则表达式 1yum install -y pcre pcre-devel (3)zlib压缩和解压缩依赖， 1yum install -y zlib zlib-devel (4)SSL 安全的加密的套接字协议层，用于HTTP安全传输，也就是https 1yum install -y openssl openssl-devel 解压，需要注意，解压后得到的是源码，源码需要编译后才能安装 1tar -zxvf nginx-1.16.1.tar.gz 编译之前，先创建nginx临时目录，如果不创建，在启动nginx的过程中会报错 1mkdir /var/temp/nginx -p 在nginx目录，输入如下命令进行配置，目的是为了创建makefile文件 1cd nginx-1.16.1 12345678910111213./configure \--prefix=/usr/local/nginx \--pid-path=/var/run/nginx/nginx.pid \--lock-path=/var/lock/nginx.lock \--error-log-path=/var/log/nginx/error.log \--http-log-path=/var/log/nginx/access.log \--with-http_gzip_static_module \--http-client-body-temp-path=/var/temp/nginx/client \--http-proxy-temp-path=/var/temp/nginx/proxy \--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \--http-scgi-temp-path=/var/temp/nginx/scgi \--add-module=/home/software/fdfs/fastdfs-nginx-module-1.22/src 主要新增一个第三方模块 修改 mod_fastdfs.conf 配置文件 12345base_path=/usr/local/fastdfs/tmptracker_server=(trackerip):22122group_name=groupTesturl_have_group_name = truestore0_path=/usr/local/fastdfs/storage 1mkdir /usr/local/fastdfs/tmp 修改nginx.conf，添加如下虚拟主机： 123456789server &#123; listen 8888; server_name localhost; location /groupTest/M00 &#123; ngx_fastdfs_module; &#125; &#125; make编译 1make 安装 1make install 进入sbin目录启动nginx 1./nginx 停止：./nginx -s stop 重新加载：./nginx -s reload 浏览器测试浏览器输入地址 12例：http://10.10.10.115:8888/groupTest/M00/00/00/CgoKc17sIdSAIZ6pADfje97FrYA794.JPGhttp://(storageip):8888/groupTest/M00/00/00/(imagename) SpringBoot集成FastDFS###引入依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.github.tobato/fastdfs-client --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt; &lt;version&gt;1.26.6&lt;/version&gt;&lt;/dependency&gt; ###application.yml中加入配置 123456789############################################################## fdfs 配置#############################################################fdfs: connect-timeout: 30 # 连接的超时时间 so-timeout: 30 # 读取的超时时间 tracker-list: (trackerip):22122 # tracker服务所在的ip地址和端口号 文件上传service12345678910111213141516171819202122232425262728293031323334package com.gy.service.impl;import com.github.tobato.fastdfs.domain.fdfs.StorePath;import com.github.tobato.fastdfs.service.FastFileStorageClient;import com.gy.service.FdfsService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.web.multipart.MultipartFile;import java.io.InputStream;@Servicepublic class FdfsServiceImpl implements FdfsService &#123; @Autowired private FastFileStorageClient fastFileStorageClient; @Autowired private FileResource fileResource; @Override public String upload(MultipartFile file, String fileExtName) throws Exception &#123; StorePath storePath = fastFileStorageClient.uploadFile(file.getInputStream(), file.getSize(), fileExtName, null); String path = storePath.getFullPath(); return path; &#125; &#125; ###String转MultipartFile 工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package com.course.server.util;import org.springframework.web.multipart.MultipartFile;import sun.misc.BASE64Decoder;import java.io.*;public class Base64ToMultipartFile implements MultipartFile &#123; private final byte[] imgContent; private final String header; public Base64ToMultipartFile(byte[] imgContent, String header) &#123; this.imgContent = imgContent; this.header = header.split(";")[0]; &#125; @Override public String getName() &#123; // TODO - implementation depends on your requirements return System.currentTimeMillis() + Math.random() + "." + header.split("/")[1]; &#125; @Override public String getOriginalFilename() &#123; // TODO - implementation depends on your requirements return System.currentTimeMillis() + (int) Math.random() * 10000 + "." + header.split("/")[1]; &#125; @Override public String getContentType() &#123; // TODO - implementation depends on your requirements return header.split(":")[1]; &#125; @Override public boolean isEmpty() &#123; return imgContent == null || imgContent.length == 0; &#125; @Override public long getSize() &#123; return imgContent.length; &#125; @Override public byte[] getBytes() throws IOException &#123; return imgContent; &#125; @Override public InputStream getInputStream() throws IOException &#123; return new ByteArrayInputStream(imgContent); &#125; @Override public void transferTo(File dest) throws IOException, IllegalStateException &#123; new FileOutputStream(dest).write(imgContent); &#125; public static MultipartFile base64ToMultipart(String base64) &#123; try &#123; String[] baseStrs = base64.split(","); BASE64Decoder decoder = new BASE64Decoder(); byte[] b = new byte[0]; b = decoder.decodeBuffer(baseStrs[1]); for(int i = 0; i &lt; b.length; ++i) &#123; if (b[i] &lt; 0) &#123; b[i] += 256; &#125; &#125; return new Base64ToMultipartFile(b, baseStrs[0]); &#125; catch (IOException e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; controller 1234@RequestMapping("/upload")public ResponseDto upload(String shardBase64) throws Exception &#123; MultipartFile shard = Base64ToMultipartFile.base64ToMultipart(shardBase64);&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[maven]]></title>
    <url>%2F2019%2F07%2F27%2Fmaven%2F</url>
    <content type="text"><![CDATA[maven介绍]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门]]></title>
    <url>%2F2019%2F07%2F26%2FSpringBoot%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[activeMQ详解]]></title>
    <url>%2F2019%2F07%2F25%2FactiveMQ%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[ActiveMQ基本概念12345678Producer:（生产者)Consumer:（消费者）Queues:队列消息，也叫点对点消息 Number of Pending Message：没有消费的消息数量 Number of Consumers：连接得消费者 Messages Enqueued：进入到队列中得消息数量 Messages Dequeued：已经出列得消息数量Topics:订阅消息, 类似广播的消息 消息中间件(MOM)概念12利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。面向消息的中间件（MOM），提供了以松散耦合的灵活方式集成应用程序的一种机制。 常见消息中间件（1）ActiveMQ12ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现。 （2）RabbitMQ12AMQP协议的领导实现，支持多种场景。淘宝的MySQL集群内部有使用它进行通讯，OpenStack开源云平台的通信组件，最先在金融行业得到运用。 （3）ZeroMQ1史上最快的消息队列系统 （4）Kafka1234Apache下的一个子项目特点： 高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率； 完全的分布式系统。适合处理海量数据。 消息中间件的传递模式点对点模式(Queue)概念12Point-to-Point(P2P)我们很容易理解，即生产者和消费者之间的消息往来。每个消息都被发送到特定的消息队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。 特点 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)； 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列； 接收者在成功接收消息之后需向队列应答成功。 Pub/Sub模式(发布-订阅—Topic)概念1类似广播 特点 每个消息可以有多个消费者； 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态； JMS协议概念1JMS是Java Message Service的缩写，即Java消息服务 特点1、定义一组消息公用概念和实用工具 1所有Java应用程序都可以使用JMS中定义的API去完成消息的创建、接收与发送，任何实现了JMS标准的MOM都可以作为消息的中介，完成消息的存储转发 2、最大化消息应用程序的可移植性 1MOM提供了有保证的消息发送，应用程序开发人员无需了解远程过程调用（RPC）和网络/通信协议的细节，提供了程序的可移植性 3、最大化降低应用程序与应用程序之间的耦合度 1234567由于MOM的存在，各个应用程序只关心和MOM之间如何进行消息的接收与发送，而无须关注MOM的另一边，其他程序是如何接收和发送的JMS定义了一套通用的接口和相关语义，提供了诸如持久、验证和事务的消息服务，它最主要的目的是允许Java应用程序访问现有的消息中间件。JMS规范没有指定在消息节点间所使用的通讯底层协议，来保证应用开发人员不用与其细节打交道，一个特定的JMS实现可能提供基于TCP/IP、HTTP、UDP或者其它的协议。由于没有统一的规范和标准，基于消息中间件的应用不可移植，不同的消息中间件也不能互操作，这大大阻碍了消息中间件的发展。 Java Message Service(JMS, Java消息服务)是SUN及其伙伴公司提出的旨在统一各种消息中间件系统接口的规范。目前许多厂商采用并实现了JMS API，现在，JMS产品能够为企业提供一套完整的消息传递功能，目前我们看到的比较流行的JMS商业软件和开源产品：WebLogic、SonicMQ、ActiveMQ、OpenJMS都是基于JMS规范的实现 JMS消息模型 消息头（header）：JMS消息头包含了许多字段，它们是消息发送后由JMS提供者或消息发送者产生，用来表示消息、设置优先权和失效时间等等，并且为消息确定路由。 属性（property）：由消息发送者产生，用来添加删除消息头以外的附加信息。 消息体（body）：由消息发送者产生，JMS中定义了5种消息体：ByteMessage、MapMessage、ObjectMessage、StreamMessage和TextMessage。 JMS标准详情 JMS标准 点对点模式 发布/订阅模式 ConnectionFactory QueueConnectionFactory TopicConnectionFactory Connection QueueConnection TopicConnection Destination Queue Topic Session QueueSession TopicSession MessageProducer QueueSender TopicPublisher MessageConsumer QueueReceiver TopicSubscriber API解释 要 素 作 用 Destination 表示消息所走通道的目标定义，用来定义消息从发送端发出后要走的通道，而不是接收方。Destination属于管理类对象 ConnectionFactory 顾名思义，用于创建连接对象，ConnectionFactory属于管理类的对象 Connection 连接接口，所负责的重要工作是创建Session Session 会话接口，这是一个非常重要的对象，消息发送者、消息接收者以及消息对象本身，都是通过这个会话对象创建的 MessageConsumer 消息的消费者，也就是订阅消息并处理消息的对象 MessageProducer 消息的生产者，也就是用来发送消息的对象 XXXMessage 指各种类型的消息对象，包括ByteMesage、ObjectMessage、StreamMessage和TextMessage这5种 Message类型 TextMessage–一个字符串对象 MapMessage–一套名称-值对 ObjectMessage–一个序列化的 Java 对象 BytesMessage–一个字节的数据流 StreamMessage – Java 原始值的数据流 ActiveMQ使用ActiveMQ的原因&amp;ActiveMQ的特性1. 为什么用activemq123在设计分布式应用程序时，应用程序间的耦合（或称集成）方式很重要。耦合意味着两个或者多个应用程序或系统的相互依赖关系。一种简单的方式是在所有的应用程序中从架构上设计他们与其他应用程序间的交叉实现。这样必然导致，一个应用程序的改变，直接导致另一个应用程序的改变。ActiveMQ采用松耦合方式，应用程序将消息发送给ActiveMQ而并不关心什么时间以何种方式消息投递给接收者。同样的，消息接收者也不会关心消息来源于哪里和消息是怎样投递给ActiveMQ的。对于多语言编写的复杂应用环境中，允许客户端使用不同的编程语言甚至不同的消息包装协议。ActiveMQ作为消息的中间件，允许复杂的多语言应用程序以一种一步的方式集成和交互。所以说，ActiveMQ是一种好的，提供松散耦合的，能够为多语言交叉应用提供集成的中间件。 2. 什么时候用activemq123ActiveMQ的设计目标是提供标准的，面向消息的，能够跨越多语言和多系统的应用集成消息通信中间件。大多数情况下ActiveMQ被用于做系统之间的数据交换。只要是两个应用程序间需要通信的情况，都可以考虑使用JMS，不论这种通信是在本地的（就是通信的两个应用程序在同一台主机上），还是分布在不同机器上。尽管是在同一个主机上的两个应用程序需要通信也可以使用ActiveMQ。ActiveMQ可以确保消息投递成功并采用异步方式通信。 3. activemq特性 支持JMS规范：ActiveMQ完全实现了JMS1.1规范。 连接方式的多样化：ActiveMQ提供了广泛的连接模式，包括HTTP/S、JGroups、JXTA、muticast、SSL、TCP、UDP、XMPP等。提供了如此多的连接模式表明了ActiveMQ具有较高的灵活性。 与其他的Java容器紧密集成：ActiveMQ提供了和其它流行的Java容器的结合，包括Apache Geronimo、Apache Tomcat、JBoss、Jetty等。 客户端API：ActiveMQ提供了多种客户端可访问的API，包括Java、C/C++，.NET，Perl、PHP、Python、Ruby等。当然，ActiveMQ中介必须运行在Java虚拟机中，但是使用它的客户端可以使用其他的语言来实现。 中介集群：多个ActiveMQ中介可以一起协同工作，来完成某项复杂的工作，这被称为网络型中介（network of brokers），这种类型的中介将会支持多种拓扑类型。 ActiveMQ-Demomaven-pom依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.14.5&lt;/version&gt;&lt;/dependency&gt; ActiveMQ管理页面1234567访问地址：http://127.0.0.1:8161/用户名：admin 密码：adminQueues消息列表： Number Of Pending Messages ：等待消费的消息 这个是当前未出队列的数量。 Number Of Consumers ：消费者 这个是消费者端的消费者数量 Messages Enqueued ：进入队列的消息 进入队列的总数量,包括出队列的。 Messages Dequeued ：出了队列的消息 可以理解为是消费这消费掉的数量。 发送&amp;接收消息开发步骤12345678910 //发送&amp;接收消息的9个步骤//1.创建连接工厂//2.获取连接//3.启动连接//4.获取session//5.创建队列对象//6.创建消息生产者对象或消费者//7.创建消息 //接受消息setMessageListener//8.使用生成者发送消息 //等待键盘输入System.in.read();//9.关闭资源 QueueQueue点对点生产者发送message1234567891011121314151617181920//1.创建连接工厂ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp:127.0.0.1:61616");//2.获取连接Connection connection = connectionFactory.createConnection();//3.启动连接connection.start();//4.获取sessionSession session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5.创建队列对象Queue queue = session.createQueue("test-queue");//6.创建消息生产者对象或消费者MessageProducer producer = session.createProducer(queue);//7.创建消息TextMessage textMessage = session.createTextMessage("欢迎来到品优购的世界");//8.使用生成者发送消息producer.send(textMessage);//9.关闭资源producer.close();session.close();connection.close(); Queue点对点消费者接收message12345678910111213141516171819202122232425262728293031//1.创建连接工厂ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp:127.0.0.1:61616");//2.获取连接Connection connection = connectionFactory.createConnection();//3.启动连接connection.start();//4.获取sessionSession session = connection.createSession();//5.创建队列对象Queue queue = session.createQueue("test-queue");//6.创建消息生产者对象或消费者MessageConsumer consumer = session.createConsumer(queue);//7.接受消息setMessageListenerconsumer.setMessageLinstener(new MessageListener()&#123; public void onMessage(Message message)&#123; //获取文本消息对象 TextMessage textMessage = (TextMessage) message; try&#123; //提取文本 String text = textMessage.getText(); &#125;catch(JMSException e)&#123; e.printStackTrace(); &#125; &#125;&#125;)//8.等待键盘输入System.in.read();System.in.read();//9.关闭资源consumer.close();session.close();connection.close(); TopicTopic订阅生产者广播Message1234567891011121314151617181920//1.创建连接工厂ActiveMQConnectionFactory connectionFactory = new ActiveMQConectionFactory();//2.获取连接Connection connection = connectionFactory.createConnection();//3.启动连接connection.start();//4.获取sessionSession session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5.创建一个订阅Topic topic = session.createTopic("test-topic");//6.创建消息生产者MessageProducer producer = session.createProducer(topic);//7.创建消息TextMessage textMessage = session.createTextMessage("您的手机没话费了");//8.使用生成者发送消息producer.send(textMessage);//9.关闭资源producer.close();session.close();connection.close(); Topic订阅消费者接收Message123456789101112131415161718192021222324//1.创建连接工厂ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://127.0.0.1:61616");//2.获取连接Connection connection = connectionFactory.createConnection();//3.启动连接connection.start();//4.获取sessionSession session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE);//5.创建队列对象Topic topic = session.createTopic("test-topic");//6.创建订阅消费者Consumer consumer = session.createConsumer(topic);//7.接受消息setMessageListenerconsumer.setMessageLinstener(new MessageListener()&#123; public void onMessage(Message message)&#123; TextMessage = (TextMessage) message; &#125;&#125;);//8.等待键盘输入System.in.read();System.in.read();//9.关闭资源consumer.close();session.close();connection.close(); 注意123Topic消息的消费方必须先于消息的生产方启动才可以正常接收到消息 因为Topic发送方会根据注册的情况主动把消息推送到订阅过该消息的消费者。 先启动接收方，接收方会去ActiveMQ的客户端注册，注册过后消息的发送方会创建两个临时消息生产者把消息推送到消息的在客户端注册过的接收方 ActiveMQ的消息选择器123456789101112131415161718生产者在header或properties中添加应用程序特有的属性，消费者根据属性的值来选择是否接收消息（过滤）。语法和使用规范： 生产者： 可接收的类型包括：byte,int,double,boolean,String; 具体代码实现： TextMessage message = session.createTextMessage(); message.setIntProperty("test",2); message.setText("test"); 消费者： 具体代码实现： consumer = session.createConsumer(destination,"test &gt; 2"); 消费者的拦截器中的部分可以写条件表达式、算术表达式、比较运算符( = , &gt; , &gt;= , &lt; , &lt;= , &lt;&gt;)和逻辑运算符(NOT , AND , OR)组成的表达式： session.createConsumer(destination,"name IS NULL"); session.createConsumer(destination,"name IS NOT NULL"); session.createConsumer(destination,"age BETWEEN 20 AND 30"); session.createConsumer(destination,"address NOT IN ('US','UK','France')");属性标识符要么在heads中定义 要么在 properties中定义，如果在sender中是在heads中定义而receiver中却从properties中寻找的话，找不到的情况下他是不会自动去heads中寻找的，而是会返回null； ActiveMQ的消息确认机制12345jms消息只有在被消费者确认之后才会认为成功消费了这条消息。消息的成功消费通常包括三个步骤：（1）client接收消息（2）client处理消息（3）消息被确认（也就是client确认消息） 事务性会话在事务性会话中当一个事务被提交的时候，确认自动发生。（ps:异步消息接收中不能使用事务性会话）。 非事务性会话在非事务性会话中消息何时被确认取决于创建的session中设置的消息应答模式（acknowledge model） acknowledge model的三个值，（三种确认模式）Session.AUTO_ACKNOWLEDGE：当client端成功的从receive方法或从onMessage(Message message) 方法返回的时候，会话自动确认client收到消息。 Session.CLIENT_ACKNOWLEDGE:客户单通过调用acknowledge方法来确认客户端收到消息。但需要注意在这种应答模式下，确认是在会话层上进行的，确认一个被消费的消息将自动确认所有已消费的其他消息。比如一个消费者已经消费了10条消息，然后确认了第5条消息被消费，则这10条都被确认消费了。 12345678910111213141516171819//acknowledge（）通知方法是在Message对象上: //同步接收，调用acknowledge（）方法进行确认： consumer = session.createConsumer(queue); Message message = consumer.receive(); message.acknowledge(); //异步接收，调用acknowledge（）方法进行确认： consumer.setMessageListener(new MessageListener() &#123; @Override public void onMessage(Message message) &#123; TextMessage textMessage = (TextMessage) message; try &#123; String value = textMessage.getText(); System.out.println("value: " + value); message.acknowledge(); //消息消费确认通知 &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); Session.DUPS_ACKNOWLEDGE：不是必须签收，消息可能会重复发送。在第二次重新传送消息的时候，消息头的JmsDelivered会被置为true标示当前消息已经传送过一次，客户端需要进行消息的重复处理控制。 JMS消息的持久化JMS 支持以下两种消息提交模式：PERSISTENT,NON_PERSISTENT PERSISTENT123是activemq默认的传送方式，此方式下的消息在配合activemq.xml中配置的消息存储方式，会被存储在特定的地方，直到有消费者将消息消费或者消息过期进入DLQ队列，消息生命周期才会结束。此模式下可以保证消息只会被成功传送一次和成功使用一次，消息具有可靠性。在消息传递到目标消费者，在消费者没有成功应答前，消息不会丢失。所以很自然的，需要一个地方来持久性存储。如果消息消费者在进行消费过程发生失败，则消息会被再次投递。DeliveryMode.PERSISTENT 指示JMS provider持久保存消息，以保证消息不会因为JMS provider的失败而丢失。 消息持久化在硬盘中，ActiveMQ持久化有三种方式：AMQ、KahaDB、JDBC。 ActiveMQ持久化的三种方式AMQ1AMQ是一种文件存储形式，它具有写入速度快和容易恢复的特点。消息存储在一个个文件中，文件的默认大小为32M，如果一条消息的大小超过了32M，那么这个值必须设置大一点。当一个存储文件中的消息已经全部被消费，那么这个文件将被标识为可删除，在下一个清除阶段，这个文件被删除。AMQ适用于ActiveMQ5.3之前的版本。 KahaDB1KahaDB是基于文件的本地数据库储存形式，虽然没有AMQ的速度快，但是它具有强扩展性，恢复的时间比AMQ短，从5.4版本之后KahaDB做为默认的持久化方式。 JDBC1可以将消息存储到数据库中，例如：Mysql、SQL Server、Oracle、DB2。 NON_PERSISTENT123非持久的消息适用于不重要的，可以接受消息丢失的哪一类消息，这种消息只会被投递一次，消息不会在持久性存储中存储，也不会保证消息丢失后的重新投递。DeliveryMode.NON_PERSISTENT 不要求JMS provider持久保存消息，消息存放在内存中，读写速度快，在JMS服务停止后消息会消失，没有持久化到硬盘。 ActiveMQ的持久化12345发送者将消息发送出去后，消息中心首先将消息存储到本地数据文件、内存数据库或者远程数据库等，然后试图将消息发送给接收者，发送成功则将消息从存储中删除，失败则继续尝试。消息中心启动以后首先要检查指定的存储位置，如果有未发送成功的消息，则需要把消息发送出去。配置持久化的方式，都是修改安装目录下conf/activemq.xml文件 JDBC方式使用JDBC持久化方式，数据库会创建3个表：activemq_msgs，activemq_acks和activemq_lock。 activemq_msgs用于存储消息，Queue和Topic都存储在这个表中。 conf/activemq.xml123&lt;persistenceAdapter&gt; &lt;jdbcPersistenceAdapter dataSource="dataSource" createTablesOnStartup="false" /&gt; &lt;/persistenceAdapter&gt; dataSource指定持久化数据库的bean，createTablesOnStartup是否在启动的时候创建数据表，默认值是true，这样每次启动都会去创建数据表了，一般是第一次启动的时候设置为true，之后改成false。 数据库表信息123456789101112131415161718192021activemq_msgs用于存储消息，Queue和Topic都存储在这个表中：ID：自增的数据库主键CONTAINER：消息的DestinationMSGID_PROD：消息发送者客户端的主键MSG_SEQ：是发送消息的顺序，MSGID_PROD+MSG_SEQ可以组成JMS的MessageIDEXPIRATION：消息的过期时间，存储的是从1970-01-01到现在的毫秒数MSG：消息本体的Java序列化对象的二进制数据PRIORITY：优先级，从0-9，数值越大优先级越高activemq_acks用于存储订阅关系。如果是持久化Topic，订阅者和服务器的订阅关系在这个表保存：主要的数据库字段如下：CONTAINER：消息的DestinationSUB_DEST：如果是使用Static集群，这个字段会有集群其他系统的信息CLIENT_ID：每个订阅者都必须有一个唯一的客户端ID用以区分SUB_NAME：订阅者名称SELECTOR：选择器，可以选择只消费满足条件的消息。条件可以用自定义属性实现，可支持多属性AND和OR操作LAST_ACKED_ID：记录消费过的消息的ID。表activemq_lock在集群环境中才有用，只有一个Broker可以获得消息，称为Master Broker，其他的只能作为备份等待Master Broker不可用，才可能成为下一个Master Broker。这个表用于记录哪个Broker是当前的Master Broker。 AMQ方式性能高于JDBC，写入消息时，会将消息写入日志文件，由于是顺序追加写，性能很高。为了提升性能，创建消息主键索引，并且提供缓存机制，进一步提升性能。每个日志文件的大小都是有限制的（默认32m，可自行配置）。 当超过这个大小，系统会重新建立一个文件。当所有的消息都消费完成，系统会删除这个文件或者归档（取决于配置）。 主要的缺点是AMQ Message会为每一个Destination创建一个索引，如果使用了大量的Queue，索引文件的大小会占用很多磁盘空间。 而且由于索引巨大，一旦Broker崩溃，重建索引的速度会非常慢。 虽然AMQ性能略高于Kaha DB方式，但是由于其重建索引时间过长，而且索引文件占用磁盘空间过大，所以已经不推荐使用。 conf/activemq.xml123&lt;persistenceAdapter&gt; &lt;amqPersistenceAdapter directory="$&#123;activemq.data&#125;/activemq-data" maxFileLength="32mb"/&gt;&lt;/persistenceAdapter&gt; KahaDB方式KahaDB是从ActiveMQ 5.4开始默认的持久化插件，也是我们项目现在使用的持久化方式。 KahaDb恢复时间远远小于其前身AMQ并且使用更少的数据文件，所以可以完全代替AMQ。kahaDB的持久化机制同样是基于日志文件，索引和缓存。 conf/activemq.xml123&lt;persistenceAdapter&gt; &lt;kahaDB directory="$&#123;activemq.data&#125;/activemq-data" journalMaxFileLength="16mb"/&gt;&lt;/persistenceAdapter&gt; directory : 指定持久化消息的存储目录journalMaxFileLength : 指定保存消息的日志文件大小，具体根据你的实际应用配置 KahaDB支持的属性 属性名称 属性值 描述 directory activemq-data 消息文件和日志的存储目录 indexWriteBatchSize 1000 一批索引的大小，当要更新的索引量到达这个值时，更新到消息文件中 indexCacheSize 1000 内存中，索引的页大小 enableIndexWriteAsync false 索引是否异步写到消息文件中 journalMaxFileLength 32mb 一个消息文件的大小 enableJournalDiskSyncs true 是否讲非事务的消息同步写入到磁盘 cleanupInterval 30000 清除操作周期，单位ms checkpointInterval 5000 索引写入到消息文件的周期，单位ms ignoreMissingJournalfiles false 忽略丢失的消息文件，false，当丢失了消息文件，启动异常 checkForCorruptJournalFiles false 检查消息文件是否损坏，true，检查发现损坏会尝试修复 checksumJournalFiles false 产生一个checksum，以便能够检测journal文件是否损坏。 5.4版本之后有效的属性: archiveDataLogs false 当为true时，归档的消息文件被移到directoryArchive,而不是直接删除 directoryArchive null 存储被归档的消息文件目录 databaseLockedWaitDelay 10000 在使用负载时，等待获得文件锁的延迟时间，单位ms maxAsyncJobs 10000 同个生产者产生等待写入的异步消息最大量 concurrentStoreAndDispatchTopics false 当写入消息的时候，是否转发主题消息 concurrentStoreAndDispatchQueues true 当写入消息的时候，是否转发队列消息 5.6版本之后有效的属性: archiveCorruptedIndex false 是否归档错误的索引 KahaDB主要特性 日志形式存储消息； 消息索引以B-Tree结构存储，可以快速更新； 完全支持JMS事务； 支持多种恢复机制； KahaDB的结构1消息存储在基于文件的数据日志中。如果消息发送成功，变标记为可删除的。系统会周期性的清除或者归档日志文件。 消息文件的位置索引存储在内存中，这样能快速定位到。定期将内存中的消息索引保存到metadata store中，避免大量消息未发送时，消息索引占用过多内存空间。 Data logs：Data logs用于存储消息日志，消息的全部内容都在Data logs中。同AMQ一样，一个Data logs文件大小超过规定的最大值，会新建一个文件。同样是文件尾部追加，写入性能很快。每个消息在Data logs中有计数引用，所以当一个文件里所有的消息都不需要了，系统会自动删除文件或放入归档文件夹。 Metadata cache ：缓存用于存放在线消费者的消息。如果消费者已经快速的消费完成，那么这些消息就不需要再写入磁盘了。Btree索引会根据MessageID创建索引，用于快速的查找消息。这个索引同样维护持久化订阅者与Destination的关系，以及每个消费者消费消息的指针。 Metadata store在db.data文件中保存消息日志中消息的元数据，也是以B-Tree结构存储的，定时从Metadata cache更新数据。Metadata store中也会备份一些在消息日志中存在的信息，这样可以让Broker实例快速启动。即便metadata store文件被破坏或者误删除了。broker可以读取Data logs恢复过来，只是速度会相对较慢些。 LevelDB方式从ActiveMQ 5.6版本之后，又推出了LevelDB的持久化引擎。 目前默认的持久化方式仍然是KahaDB，不过LevelDB持久化性能高于KahaDB，可能是以后的趋势。 在ActiveMQ 5.9版本提供了基于LevelDB和Zookeeper的数据复制方式，用于Master-slave方式的首选数据复制方案。 spring整合ActiveMQpom依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.11.2&lt;/version&gt;&lt;/dependency&gt; spring配置123456789101112131415161718&lt;!-- 基本概念ConnectionFactory： 和jms服务器的连接, 可以是外部的jms server, 也可以使用embedded ActiveMQ Broker；Destination： 有topic和queue两种方式；JmsTemplate： spring提供的jms模板；MessageConverter： 消息转换器；MessageProducer： 消息生产者；MessageConsumer： 消息消费者；MessageListener： 消息监听器；MessageListenerContainer： 消息监听容器。Spring为我们听过了两种类型的MessageListenerContainer：SimpleMessageListenerContainer和DefaultMessageListenerContainer。SimpleMessageListenerContainer 会在一开始的时候就创建一个会话Session和消费者Consumer，并且会适用标准的JMS的MessageConsumer.setMessageListener()方法注册监听器让JMS提供调用监听器的回调函数。它不会动态的适应运行时需要和参与外部的事务管理。兼容性方面，它非常接近于独立的JMS规范，但一般不兼容J2EE的JMS限制。大多数情况下，我们还是使用DefaultMessageListenerContainer。DefaultMessageListenerContainer 与SimpleMessageListenerContainer相比，它会动态的适应运行时的需求，并且能够参与外部的事务管理。--&gt; 整合QueueapplicationContext-activemq-producer.xml123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms.xsd"&gt; &lt;context:component-scan base-package="cn.itcast.demo"&gt;&lt;/context:component-scan&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://127.0.0.1:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name="connectionFactory" ref="connectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="queueTextDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg value="queue_text"/&gt; &lt;/bean&gt; &lt;!--这个是订阅模式 文本信息--&gt; &lt;bean id="topicTextDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg value="topic_text"/&gt; &lt;/bean&gt; &lt;/beans&gt; 生产者QueueProducer123456789101112131415161718@Componentpublic class QueueProducer&#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination queueTextDestination; public void sendTextMessage(final String text)&#123; jmsTemplate.send(queueTextDestination,new MessageCreator()&#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage("spring与activeMQ整合"+text); &#125; &#125;); &#125; &#125; 生产者测试TestQueue12345678910111213@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = "classpath:applicationContext-activemq-producer.xml")public class TestQueue&#123; @Autowired private QueueProducer queueProducer; @Test public void sendTextQueue()&#123; queueProducer.sendTextMessage("是可以的"); &#125; &#125; applicationContext-activemq-consumer.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms.xsd"&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://127.0.0.1:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="queueTextDestination" class="org.apache.activemq.command.ActiveMQQueue"&gt; &lt;constructor-arg value="queue_text"/&gt; &lt;/bean&gt; &lt;!--这个是订阅消息目的地，文本信息--&gt; &lt;bean id="topicTextDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg value="topic_text"/&gt; &lt;/bean&gt; &lt;!-- 我的监听类 --&gt; &lt;bean id="myMessageListener" class="cn.itcast.demo.MyMessageListener"&gt;&lt;/bean&gt; &lt;bean id="myTopicMessageListener" class="cn.itcast.demo.MyTopicMessageListener"&gt;&lt;/bean&gt; &lt;bean id="myTopicMessageListener2" class="cn.itcast.demo.MyTopicMessageListener2"&gt;&lt;/bean&gt; &lt;!-- 消息监听容器 --&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="queueTextDestination" /&gt; &lt;property name="messageListener" ref="myMessageListener" /&gt; &lt;/bean&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="topicTextDestination" /&gt; &lt;property name="messageListener" ref="myTopicMessageListener" /&gt; &lt;/bean&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="topicTextDestination" /&gt; &lt;property name="messageListener" ref="myTopicMessageListener2" /&gt; &lt;/bean&gt; &lt;/beans&gt; 消费者MessageListener1234567891011public class MessageListener implements MessageLinstener&#123; public void onMessage(Message message)&#123; TextMessage textMessage = (TextMessage) message; String text; try&#123; text = textMessage.getText(); &#125;catch(JMSException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 消费者测试TestQueue12345678@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:applicationContext-activemq-consumer.xml")public class TestQueue &#123; @Test public void testQueue() throws IOException&#123; System.in.read(); &#125;&#125; 整合Topic生产者TopicProducer12345678910111213141516171819@Componentpublic class TopicProducer &#123; @Autowired private JmsTemplate jmsTemplate; @Autowired private Destination topicTextDestination; /** * 发送文本消息 */ public void sendTextMessage()&#123; jmsTemplate.send(topicTextDestination, new MessageCreator() &#123; public Message createMessage(Session session) throws JMSException &#123; return session.createTextMessage("通知：你的手机流量超了1个G"); &#125; &#125;); &#125;&#125; 生产者测试TestTopic123456789101112@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-activemq-producer.xml")public class TestTopic &#123; @Autowired private TopicProducer topicProducer; @Test public void sendTextQueue()&#123; topicProducer.sendTextMessage(); &#125; &#125; applicationContext-activemq-consumer-topic.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:amq="http://activemq.apache.org/schema/core" xmlns:jms="http://www.springframework.org/schema/jms" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms.xsd"&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory"&gt; &lt;property name="brokerURL" value="tcp://127.0.0.1:61616"/&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id="connectionFactory" class="org.springframework.jms.connection.SingleConnectionFactory"&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name="targetConnectionFactory" ref="targetConnectionFactory"/&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 文本信息--&gt; &lt;bean id="topicTextDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg value="topic_text"/&gt; &lt;/bean&gt; &lt;!--这个是订阅消息目的地，文本信息--&gt; &lt;bean id="topicTextDestination" class="org.apache.activemq.command.ActiveMQTopic"&gt; &lt;constructor-arg value="topic_text"/&gt; &lt;/bean&gt; &lt;!-- 我的监听类 --&gt; &lt;bean id="myMessageListener" class="cn.itcast.demo.MyMessageListener"&gt;&lt;/bean&gt; &lt;bean id="myTopicMessageListener" class="cn.itcast.demo.MyTopicMessageListener"&gt;&lt;/bean&gt; &lt;bean id="myTopicMessageListener2" class="cn.itcast.demo.MyTopicMessageListener2"&gt;&lt;/bean&gt; &lt;!-- 消息监听容器 --&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="topicTextDestination" /&gt; &lt;property name="messageListener" ref="myMessageListener" /&gt; &lt;/bean&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="topicTextDestination" /&gt; &lt;property name="messageListener" ref="myTopicMessageListener" /&gt; &lt;/bean&gt; &lt;bean class="org.springframework.jms.listener.DefaultMessageListenerContainer"&gt; &lt;property name="connectionFactory" ref="connectionFactory" /&gt; &lt;property name="destination" ref="topicTextDestination" /&gt; &lt;property name="messageListener" ref="myTopicMessageListener2" /&gt; &lt;/bean&gt; &lt;/beans&gt; 消费者测试TestTopic12345678@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations="classpath:applicationContext-activemq-topic.xml")public class TestTopic &#123; @Test public void sendTextTopic() throws IOException&#123; System.in.read(); &#125; &#125; ActiveMQ的安全机制activemq作为消息中间件这样一个独立的个体存在，连通用户和服务器。如果没有一套完备的安全机制去设置用户权限设置消息分发机制可想后果是非常严重。ActiveMQ如果不加入安全机制的话，任何人只要知道消息服务的具体地址(包括ip，端口，消息地址[队列或者主题地址，)，都可以肆无忌惮的发送、接收消息。今天我们就探讨一下他的安全机制。 1.安全机制介绍我们讨论安全机制一般包括两个部分： 验证(Authentication)：就是要验证一个用户的有效性，即用户名、密码是否正确; 授权(Authorization)：就是授予用户某种角色，以使用户只能访问具有相应角色的资源。 activemq考虑到安全方案效率问题，他提供了可插拔的安全机制，你可以使用不同的安全插件灵活为你的系统配置安全访问方式。目前activemq提供两种安全控制插件： 简单认证插件(Simple authentication plugin-in) JAAS认证插件(Java Authentication and Authorization Service) 下面我们分别就这两种插件的使用做一个说明。 2.简单认证插件简单认证插件的目的就是让用户简单配置。我们打开activemq服务的目录apache-activemq，在 conf目录下找到activemq.xml。进去找到： 123 &lt;shutdownHooks&gt; &lt;bean xmlns="http://www.springframework.org/schema/beans" class="org.apache.activemq.hooks.SpringContextHook" /&gt;&lt;/shutdownHooks&gt; 在他下面添加如下即可： 12345678&lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username="admin" password="admin" groups="users,admins"/&gt; &lt;authenticationUser username="user" password="password" groups="users"/&gt; &lt;/users&gt; &lt;/simpleAuthenticationPlugin&gt;&lt;/plugins&gt; ☆注意：此处添加的用户名和密码要和你在项目中配置的activemq用户名密码是一致的，如果在项目中不是此处已经配置过的用户发送消息的话，activemq客户端不会受理该消息。这样就达到了对非命中用户拦截的目的。 比如说你有客户端使用的用户是： 1234&lt;amq:connectionFactory id="amqConnectionFactory" brokerURL="tcp://127.0.0.1:61616" userName="admin" password="admin" /&gt; 那你就把该用户配置到activemq的配置文件中： 1&lt;authenticationUser username="admin" password="admin" groups="users,admins"/&gt; 上面是对用户进行限制，我们也可以对ip进行限制，还是在刚才的配置里面加上下面这一句： 12345678910111213&lt;plugins&gt; &lt;simpleAuthenticationPlugin&gt; &lt;users&gt; &lt;authenticationUser username="admin" password="admin" groups="users,admins"/&gt; &lt;!-- &lt;authenticationUser username="user" password="password" groups="users"/&gt; &lt;authenticationUser username="guest" password="password" groups="guests"/&gt;--&gt; &lt;/users&gt; &lt;transportConnectors&gt; &lt;transportConnector name="connection1" uri="tcp://0.0.0.0:61616" /&gt; &lt;/transportConnectors&gt; &lt;/simpleAuthenticationPlugin&gt;&lt;/plugins&gt; 0.0.0.0代表本网络中的所有主机，意味着该网段的所有主机都是可以通讯的。如果改成localhost或者127.0.0.1这种的那就只有本机了。这样我们就达到了通过IP限制的目的。 3.JAAS认证插件JAAS(Java Authentication and Authorization Service)也就是java的验证Authentication)、授权(Authorization)服务。简单来说，验证Authentication就是要验证一个用户的有效性，即用户名、密码是否正确。授权Authorization就是授予用户某种角色，可以访问哪些资源。JAASAuthentication Plugin依赖标准的JAAS机制来实现认证。通常情况下，你需要通过设置Java.security.auth.login.config系统属性来配置loginmodules的配置文件。如果没有指定这个系统属性，那么JAAS Authentication Plugin会缺省使用login.config作为文件名。 首先我们需要编写一个login.config文件： 123456activemq &#123; org.apache.activemq.jaas.PropertiesLoginModule required debug=true org.apache.activemq.jaas.properties.user=&quot;users.properties&quot; org.apache.activemq.jaas.properties.group=&quot;groups.properties&quot;; &#125;; users.properties文件： 123admin=admin user=ad1guest=ad1 group.properties文件： 123admins=admin users=user guests=guest ☆需要注意的是，PropertiesLoginModule使用本地文件的查找方式，而且查找时采用的base directory即login.config文件所在的目录，所以说这三个文件需要在同一个目录里才会找得到。另外，activemq 5.9 默认提供了以上的配置文件，在conf目录下 然后我们还是在activemq.xml配置文件中添加插件。还是上面简单插件添加的位置，添加以下插件即可，只不过你的把之前添加的简单插件注释掉。 123456789101112131415161718192021&lt;plugins&gt; &lt;jaasAuthenticationPlugin configuration="activemq-domain" /&gt; &lt;authorizationPlugin&gt; &lt;map&gt; &lt;authorizationMap&gt; &lt;authorizationEntries&gt; &lt;!-- .表示通配符,例如USERS.&gt;表示以USERS.开头的主题,&gt;表示所有主题,read表示读的权限,write表示写的权限，admin表示角色组--&gt; &lt;authorizationEntry queue="&gt;" read="admins,guests" write="guests" admin="admins,guests" /&gt; &lt;authorizationEntry queue="USERS.&gt;" read="users" write="users" admin="users" /&gt; &lt;authorizationEntry queue="GUEST.&gt;" read="guests" write="guests,users" admin="guests,users" /&gt; &lt;authorizationEntry topic="&gt;" read="admins" write="admins" admin="admins" /&gt; &lt;authorizationEntry topic="USERS.&gt;" read="users" write="users" admin="users" /&gt; &lt;authorizationEntry topic="GUEST.&gt;" read="guests" write="guests,users" admin="guests,users" /&gt; &lt;authorizationEntry topic="ActiveMQ.Advisory.&gt;" read="guests,users" write="guests,users" admin="guests,users"/&gt; &lt;/authorizationEntries&gt; &lt;/authorizationMap&gt; &lt;/map&gt; &lt;/authorizationPlugin&gt;&lt;/plugins&gt; 添加完以上配置部分，重启avtivemq服务端，就会按照上面配置的用户进行读写的权限配置。 从上面看JAAS插件的权限分配要比简单插件的权限更加细致，不同的用户可以分别配置读写的权限，admin用户拥有创建topic或是queue的特权等等这样细致的划分，不同的用户各司其职，减少了误操作，或是刻意破换的可能性 参考：]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>activeMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务详解]]></title>
    <url>%2F2019%2F07%2F25%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[分布式事务分布式事务的解释：1分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。以上是百度百科的解释，简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性 问题产生原因1.数据库分表1当数据库单表一年产生的数据超过1000W，那么就要考虑分库分表，简单的说就是原来的一个数据库变成了多个数据库。这时候，如果一个操作既访问01库，又访问02库，而且要保证数据的一致性，那么就要用到分布式事务。 2.业务的SOA化1所谓的SOA化，就是业务的服务化。比如原来单机支撑了整个电商网站，现在对整个网站进行拆解，分离出了订单中心、用户中心、库存中心。对于订单中心，有专门的数据库存储订单信息，用户中心也有专门的数据库存储用户信息，库存中心也会有专门的数据库存储库存信息。这时候如果要同时对订单和库存进行操作，那么就会涉及到订单数据库和库存数据库，为了保证数据一致性，就需要用到分布式事务。 事务的ACID性1.原子性12在整个事务中的所有操作，要么全部成功，要么全部失败，没有中间状态。如果事务在执行的过程中发生错误，那么整个事务的所有操作都要回滚，整个事务就像没被执行过一样。 2.一致性1事务的执行必须保证系统的一致性，就拿转账为例，A有500元，B有300元，如果在一个事务里A成功转给B50元，那么不管并发多少，不管发生什么，只要事务执行成功了，那么最后A账户一定是450元，B账户一定是350元。 3.隔离性1所谓的隔离性就是说，事务与事务之间不会互相影响，一个事务的中间状态不会被其他事务感知。 事务的隔离级别1.Read uncommitted ：读未提交解释1一个事务可以读取另一个未提交事务的数据。 问题1产生脏读 事例1老板要给程序员发工资，程序员的工资是3.6万/月。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。 事例分析1实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是脏读。 2.Read committed :读提交解释1一个事务要等另一个事务提交后才能读取数据。 问题1一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。 事例1程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的… 事例分析1这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是不可重复读。 3.Repeatable read :重复读解释1重复读，就是在开始读取数据（事务开启）时，不再允许修改操作 问题1可能还会有幻读问题 事例1程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。 事例分析1重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，不可重复读对应的是修改，即UPDATE操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。 4.Serializable :序列化解释12Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。但是这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。 问题1效率低下 4.持久性1所谓的持久性，就是说一单事务完成了，那么事务对数据所做的变更就完全保存在了数据库中，即使发生停电，系统宕机也是如此。 分布式事务的应用场景支付1最经典的场景就是支付了，一笔支付，是对买家账户进行扣款，同时对卖家账户进行加钱，这些操作必须在一个事务里执行，要么全部成功，要么全部失败。而对于买家账户属于买家中心，对应的是买家数据库，而卖家账户属于卖家中心，对应的是卖家数据库，对不同数据库的操作必然需要引入分布式事务。 在线下单1买家在电商平台下单，往往会涉及到两个动作，一个是扣库存，第二个是更新订单状态，库存和订单一般属于不同的数据库，需要使用分布式事务保证数据一致性。 解决方案消息事务+最终一致性1基于消息中间件的两阶段提交,需要业务系统结合 MQ 消息中间件实现，在实现过程中需要保 证消息的成功发送及成功消费。即需要通过业务系统控制MQ 的消息状态 TCC编程模式1所谓的TCC编程模式，也是两阶段提交的一个变种。TCC提供了一个编程框架，将整个业务逻辑分为三块：Try、Confirm和Cancel三个操作。以在线下单为例，Try阶段会去扣库存，Confirm阶段则是去更新订单状态，如果更新订单失败，则进入Cancel阶段，会去恢复库存。总之，TCC就是通过代码人为实现了两阶段提交，不同的业务场景所写的代码都不一样，复杂度也不一样，因此，这种模式并不能很好地被复用。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[POI用法详解]]></title>
    <url>%2F2019%2F07%2F25%2FPOI%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[POI简介1234567891011121314目前常见读写Excel的工具类开源javaAPI有两种方式，一个是JXL（Java Excel API） 官网地址：http://jexcelapi.sourceforge.net/一个是Apache的POI（Poor Obfuscation Implementation）官网地址：http://poi.apache.org/POI支持微软的OLE2格式文件Office 2003及以下版本；同时支持微软的OOXML（Office Open XML）标准，也就是Office 2007以上版本。JXL只能实现对Excel 2003以下版本的支持。POI使用HSSF对象操作OLE2格式Excel，文件后缀为.xls的；使用XSSF、SXSSF对象操作OOXML格式Excel，文件后缀为.xlsx的。对于OLE2版本的Excel，一个Sheet工作表它的行最多支持到65536行，列支持到256列；对于OOXML版本的Excel，一个Sheet工作表它的行支持到1048576行，列支持到16384列。 三种workbook基本使用方法&amp;核心API12345678910111213141516171819202122232425262728293031// 工作簿操作//新建工作簿WorkBook book = new HSSFWorkBook();//打开工作簿WorkBook book = new HSSFWorkBook(new FileInputStream(xlsFile));//建立新的sheet对象HSSFSheet sheet = book.createSheet("sheetName");//打开第一个sheetbook.getSheetAt(0);//色织sheet的名称book.setSheetName(0,"sheetName");//创建行HSSFRow row = sheet.createRow(0);//指定列，创建单元格HSSFCell cell = row.createCell((short)0); //0行0列//设置单元格的值cell.setCellValue("cellValue");// 样式操作//获取样式对象CellStyle style = book.createCellStyle();//创建字体对象Font font = book.createFont();//设置字体大小font.setFontHeightlnPoints((short)16);//设置字体类型font.setFontName("楷体");//将字体设置到stylestyle.setFont(font);//将样式设置到单元格cell.setCellStyle(style); 字体修饰1234567891011121314151617181920212223//设置单元格样式private HSSFCellStyle Style(HSSFWorkbook wb)&#123; HSSFCellStyle curStyle = wb.createCellStyle(); HSSFFont curFont = wb.createFont(); //设置字体 //curFont.setFontName("Times New Roman"); //设置英文字体 curFont.setFontName("微软雅黑"); //设置英文字体 curFont.setCharSet(HSSFFont.DEFAULT_CHARSET); //设置中文字体，那必须还要再对单元格进行编码设置 curFont.setFontHeightInPoints((short)10); //字体大小 curFont.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD); //加粗 curStyle.setFont(curFont); curStyle.setBorderTop(HSSFCellStyle.BORDER_THICK); //粗实线 curStyle.setBorderBottom(HSSFCellStyle.BORDER_THIN); //实线 curStyle.setBorderLeft(HSSFCellStyle.BORDER_MEDIUM); //比较粗实线 curStyle.setBorderRight(HSSFCellStyle.BORDER_THIN); //实线 curStyle.setWrapText(true); //换行 curStyle.setAlignment(HSSFCellStyle.ALIGN_RIGHT); //横向具右对齐 curStyle.setVerticalAlignment(HSSFCellStyle.VERTICAL_CENTER); //单元格垂直居中 return curStyle;&#125; 单元格操作1234567891011//纵向合并单元格 Region region = null;region = new Region(curRow-1, (short)(1), curRow-1+3, (short)1); sheet.addMergedRegion(region);//横向合并单元格CellRangeAddresssheet.addMergedRegion(new CellRangeAddress(开始行，结束行，开始列，结束列));// 横向居中style.setAlignment(CellStyle.ALIGN_CENTER); // 纵向居中style.setVerticalAlignment(CellStyle.VERTICAL_CENTER); 页面操作1234567891011121314151617181920212223242526272829303132//设置打印方向：默认纵向PrintSetup ps = sheet.getPrintSetup();ps.setLandscape(true); //横向打印//自适应列宽：//bug 对中文支持不好，列宽不够宽for(int i=0 ;i&lt;titles.length;i++)&#123; sheet.autoSizeColumn((short)i);&#125;//设置行高：nRow.setHeightInPoints(18);//设置列宽：sheet.setColumnWidth((short)colNo, (short)(256*8));//设置每列默认宽度：sheet.setDefaultColumnWidth((short) 20); //设置标题：//将第一行作为标题，即每页都打印此行 sheetN,startCol,stopCol,startRow,stopRowwb.setRepeatingRowsAndColumns(0,1,8,0,1);//页脚：HSSFFooter footer = sheet.getFooter();footer.setRight("第"+HSSFFooter.page()+"页 共"+HSSFFooter.numPages()+"页 "); //页数分页：// POI分页符有BUG，必须在模板文件中插入一个分页符，然后再此处删除预设的分页符；最后在下面重新设置分页符。// sheet.setAutobreaks(false);// int iRowBreaks[] = sheet.getRowBreaks();// sheet.removeRowBreak(3);// sheet.removeRowBreak(4);// sheet.removeRowBreak(5);// sheet.removeRowBreak(6);sheet.setRowBreak(行数); //在第startRow行设置分页符 常用字体样式方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//大标题的样式public CellStyle bigTitle(Workbook wb)&#123; CellStyle style = wb.createCellStyle(); Font font = wb.createFont(); font.setFontName("宋体"); font.setFontHeightInPoints((short)16); font.setBoldweight(Font.BOLDWEIGHT_BOLD); //字体加粗 style.setFont(font); style.setAlignment(CellStyle.ALIGN_CENTER); //横向居中 style.setVerticalAlignment(CellStyle.VERTICAL_CENTER); //纵向居中 return style;&#125;//小标题的样式public CellStyle title(Workbook wb)&#123; CellStyle style = wb.createCellStyle(); Font font = wb.createFont(); font.setFontName("黑体"); font.setFontHeightInPoints((short)12); style.setFont(font); style.setAlignment(CellStyle.ALIGN_CENTER); //横向居中 style.setVerticalAlignment(CellStyle.VERTICAL_CENTER); //纵向居中 style.setBorderTop(CellStyle.BORDER_THIN); //上细线 style.setBorderBottom(CellStyle.BORDER_THIN); //下细线 style.setBorderLeft(CellStyle.BORDER_THIN); //左细线 style.setBorderRight(CellStyle.BORDER_THIN); //右细线 return style;&#125;//文字样式public CellStyle text(Workbook wb)&#123; CellStyle style = wb.createCellStyle(); Font font = wb.createFont(); font.setFontName("Times New Roman"); font.setFontHeightInPoints((short)10); style.setFont(font); style.setAlignment(CellStyle.ALIGN_LEFT); //横向居左 style.setVerticalAlignment(CellStyle.VERTICAL_CENTER); //纵向居中 style.setBorderTop(CellStyle.BORDER_THIN); //上细线 style.setBorderBottom(CellStyle.BORDER_THIN); //下细线 style.setBorderLeft(CellStyle.BORDER_THIN); //左细线 style.setBorderRight(CellStyle.BORDER_THIN); //右细线 return style;&#125; Zip的方式导出POI12345SXSSFWorkbook workbook = new SXSSFWorkbook(100);ZipOutputStream zipOut = new ZipOutputStream(request.getOutputStream());workbook.createSheet("...");zipOut.workbook.write(zipOut);]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>POI</tag>
      </tags>
  </entry>
</search>
